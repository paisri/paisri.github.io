---
layout: page
title: Publications
---

# Academic Publications and Preprints

- Robustness to fundamental uncertainty in AGI alignment

# General audience

- [Avoiding AI Races Through Self-Regulation](https://mapandterritory.org/avoiding-ai-races-through-self-regulation-1b815fca6b06) - Runner up to the [Solving the AI Race General AI Challenge](https://medium.com/goodai-news/solving-the-ai-race-finalists-15-000-of-prizes-5f57d1f6a45f)
- [Computational Complexity of P-Zombies](https://mapandterritory.org/computational-complexity-of-p-zombies-fc56909af96f)
- [AI Alignment and Phenomenal Consciousness](https://mapandterritory.org/ai-alignment-and-phenomenal-consciousness-2ca23de6aebd)
- [Formally Stating the AI Alignment Problem](https://mapandterritory.org/formally-stating-the-ai-alignment-problem-fe7a6e3e5991)
- [Towards and Axiological Approach to AI Alignment](https://mapandterritory.org/towards-an-axiological-approach-to-ai-alignment-4993d044d1b8)

# Notes

- [Safety in Machine Learning](https://www.lesswrong.com/posts/3iP8P57mNpHBFfYkd/safety-in-machine-learning)
- [Thoughts on "AI Safety via Debate"](https://www.lesswrong.com/posts/WRy6KNnxwQHc5Ktjc/thoughts-on-ai-safety-via-debate)
- [How safe "safe" AI development?](https://www.lesswrong.com/posts/JDZsoykx3KBp8ptEi/how-safe-safe-ai-development)
